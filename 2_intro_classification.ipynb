{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2_intro_classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePLSo3ldhbMO",
        "colab_type": "text"
      },
      "source": [
        "# Classification example\n",
        "UCI Wine recognition dataset. Three-class classification.\n",
        "\n",
        "More information about the data here: https://scikit-learn.org/stable/datasets/index.html#wine-dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j97rMXHehbfe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        },
        "outputId": "542ea8fd-798e-49dc-e501-b4281178ac61"
      },
      "source": [
        "# Import packages\n",
        "import numpy as np\n",
        "import sklearn.datasets\n",
        "import sklearn.linear_model\n",
        "\n",
        "# Reproducible results\n",
        "np.random.seed(42)\n",
        "\n",
        "data = sklearn.datasets.load_wine()\n",
        "\n",
        "n_train = int(data.data.shape[0] * 0.75 + 0.5)\n",
        "n_val = int(data.data.shape[0] * 0.15 + 0.5)\n",
        "n_test = int(data.data.shape[0] * 0.10 + 0.5) - 1\n",
        "\n",
        "X = data.data[:n_train, :]\n",
        "y = data.target[:n_train]\n",
        "X_val = data.data[n_train:n_train + n_val, :]\n",
        "y_val = data.target[n_train:n_train + n_val]\n",
        "# Note! Do not touch the test data until the very end!\n",
        "X_test = data.data[n_train + n_val:, :]\n",
        "y_test = data.target[n_train + n_val:]\n",
        "\n",
        "print(f\"Training set size X  : {X.shape}\")\n",
        "print(f\"Training set size y  : {y.shape}\")\n",
        "print(f\"Validation set size X: {X_val.shape}\")\n",
        "print(f\"Validation set size y: {y_val.shape}\")\n",
        "print(f\"Test set size X      : {X_test.shape}\")\n",
        "print(f\"Test set size y      : {y_test.shape}\")\n",
        "print(f\"Output classes       : {set(y)}\")\n",
        "print(f\"Feature names        : {data.feature_names}\")"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set size X  : (134, 13)\n",
            "Training set size y  : (134,)\n",
            "Validation set size X: (27, 13)\n",
            "Validation set size y: (27,)\n",
            "Test set size X      : (17, 13)\n",
            "Test set size y      : (17,)\n",
            "Output classes       : {0, 1, 2}\n",
            "Feature names        : ['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', 'total_phenols', 'flavanoids', 'nonflavanoid_phenols', 'proanthocyanins', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6J7KKDQjiNjo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Task1: Preprocess the data\n",
        "#  - Try without preprovessing, try with different kinds.\n",
        "#  - Evaluate on the validation data\n",
        "standard_scaler = sklearn.preprocessing.StandardScaler()\n",
        "standard_scaler.fit(X)\n",
        "X_ = standard_scaler.transform(X)\n",
        "X_val_ = standard_scaler.transform(X_val)\n",
        "X_test_ = standard_scaler.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5oIaLx3i3OP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fit baseline model\n",
        "model_baseline = sklearn.linear_model.LogisticRegression(\n",
        "    penalty=\"none\",\n",
        "    tol=0.0001,\n",
        "    fit_intercept=True,\n",
        "    solver=\"lbfgs\",\n",
        "    max_iter=100,\n",
        "    multi_class=\"multinomial\")\n",
        "_ = model_baseline.fit(X_, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bC0_DAq4kHkc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "5dc0467e-4241-415c-a2d2-5b252c1c5a18"
      },
      "source": [
        "# Evaluate baseline model\n",
        "yhat = model_baseline.predict(X_)\n",
        "yhat_val = model_baseline.predict(X_val_)\n",
        "acc = sklearn.metrics.accuracy_score(y, yhat)\n",
        "acc_val = sklearn.metrics.accuracy_score(y_val, yhat_val)\n",
        "print(f\"Training data accuracy  : {acc}\")\n",
        "print(f\"Validation data accuracy: {acc_val:.2f}\")"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training data accuracy  : 1.0\n",
            "Validation data accuracy: 0.59\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_iqH_Kj24hDG",
        "colab_type": "text"
      },
      "source": [
        "The model does not make any errors on the training data, and a larger error on the validation data. What does this mean? Can we do anything about it?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZJVGDWpkx2-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Task 2: Find a better model\n",
        "#  - Try different classification methods\n",
        "#  - Evaluate them on the validation data\n",
        "#  - Beat the baseline model and select the best one you can find\n",
        "\n",
        "model = \"... add your code here!\"\n",
        "\n",
        "_ = model.fit(X_, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rnq0G3f7lJ8T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "611b0f33-3a7f-4240-e0ca-b752a282604d"
      },
      "source": [
        "# Evaluate better model\n",
        "yhat = model.predict(X_)\n",
        "yhat_val = model.predict(X_val_)\n",
        "acc = sklearn.metrics.accuracy_score(y, yhat)\n",
        "acc_val = sklearn.metrics.accuracy_score(y_val, yhat_val)\n",
        "print(f\"Training data accuracy  : {acc}\")\n",
        "print(f\"Validation data accuracy: {acc_val:.2f}\")"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training data accuracy  : 1.0\n",
            "Validation data accuracy: 0.26\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOGfQmWFlVKT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Task 3: Determine the importance of the input variables\n",
        "# ... your code here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuQfK309lkf4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "4e2c2d52-97cc-4e15-e056-2bd0e1ea91af"
      },
      "source": [
        "# Evaluate the final model on the test data.\n",
        "# This is only ever done once, and as the last thing we do.\n",
        "# Training another model after this, based on the performance on the test data\n",
        "# leads to biased results.\n",
        "yhat = model.predict(X_)\n",
        "yhat_val = model.predict(X_val_)\n",
        "yhat_test = model.predict(X_test_)\n",
        "acc = sklearn.metrics.accuracy_score(y, yhat)\n",
        "acc_val = sklearn.metrics.accuracy_score(y_val, yhat_val)\n",
        "acc_test = sklearn.metrics.accuracy_score(y_test, yhat_test)\n",
        "print(f\"Training data accuracy  : {acc}\")\n",
        "print(f\"Validation data accuracy: {acc_val}\")\n",
        "print(f\"Test data accuracy      : {acc_test}\")"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training data accuracy  : 1.0\n",
            "Validation data accuracy: 0.25925925925925924\n",
            "Test data accuracy      : 0.35294117647058826\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avEPMzHxlvg8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}